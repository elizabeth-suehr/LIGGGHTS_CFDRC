#----------------------------------------------------------------------
# LICENSE Date: 11-09-2021
# This file is part of the CFDRC LIGGGHTS-CUSTOM software
# Copyright 2021.
# This software tool is being furnished to NASA Personnel under 
# SBIR Data Rights. The SBIR Data Rights are asserted by CFD 
# Research Corporation.
# Distribution C: Limited to Government Employees only.
# A release under Distribution B and A is being considered and
# may be done for future releases of the code.
#
# For more information, contact:
#
# Manuel P. Gale (manuel.gale@cfd-research.com), 256-726-4860.
#
# These SBIR data are furnished with SBIR rights under
# Contract No. 80NSSC20C0219. For a period of 4 years, unless
# extended in accordance with FAR 27.409(h), after acceptance
# of all items to be delivered under this contract, the
# Government will use these data for Government purposes
# only, and they shall not be disclosed outside the
# Government (including disclosure for procurement purposes)
# during such period without permission of the Contractor,
# except that, subject to the foregoing use and disclosure
# prohibitions, these data may be disclosed for use by
# support Contractors. After the protection period, the
# Government has a paid-up license to use, and to authorize
# others to use on its behalf, these data for Government
# purposes, but is relieved of all disclosure prohibitions
# and assumes no liability for unauthorized use of these data
# by third parties. This notice shall be affixed to any
# reproductions of these data, in whole or in part.
#-------------------------------------------------------------------------

#####################################################################################################
# Description of files generated by this script
#####################################################################################################

# This Python script will generate LIGGGHTS input files and post-processing scripts
# for mixtures of spherical particles. User input should only be required in the user
# input section of the code. Each parameter is described in that section. The following
# files are generated after this script is executed (filestr is name assigned by user):
# 
# 1) 'filestr'_matrix - table showing cases generated for mixture
# 2) in.shear.'filestr'_i - LIGGGHTS shear simulation input files
# 3) in.cooling.'filestr'_i - LIGGGHTS cooling simulation input files
# 4) postProcessShear_'filestr'_i.py - post-processing script for corresponding shear input file
# 5) postProcessCooling_'filestr'_i.py - post-processing script for corresponding cooling input file
# 6) finalResults_'filestr'.py - analyze all LIGGGHTS cases and output in HDF5 format for Loci/GGFS
# 7) PBS_shear_'filestr'_i.script - PBS script for corresponding shear case
# 8) PBS_cooling_'filestr'_i.script - PBS script for corresponding cooling case
# 9) PBS_'filestr'_all.script - PBS script to run all cases sequentially

#####################################################################################################
# Begin script
#####################################################################################################
import matplotlib
matplotlib.use('Agg') # #Must be before importing matplotlib.pyplot or pylab!
params = {'legend.fontsize': 30,
          'figure.figsize': (15, 10),
          'axes.labelsize': 30,
          'axes.titlesize': 30,
          'xtick.labelsize':25,
          'ytick.labelsize':25}
matplotlib.rcParams.update(params)
from matplotlib import pyplot as plt
import sys 
import numpy as np
#import h5py
import math
from os.path import exists
import superquadrics

#####################################################################################################
# set input parameters, defaults get overwritten by user
#####################################################################################################
nspecies        = 1					# Number of species to use
proc	 	= np.array([1,1,1])		 	# Coefficients of restitution
ptype	 	= np.array([""])                	# Particle type, blank is sphere, 'superquadric' for superquadric, file name means multisphere. radius specified in file. 
nsph            = np.array([1])                         # number of spheres for body, 1 for pure sphere (not body)
# ptype	 	= np.array(["","","particle"])      	# Particle type, blank is sphere, file names means multisphere
diam	 	= np.array([0.0001])      		# Particle diameters, equivalent diameter for irregular shape
dens	 	= np.array([2500])			# Particle densities
cres	 	= np.array([0.95])		 	# Coefficients of restitution
amin            = 0.01					# Minimum volume fraction per species
amax         	= 0.5    	  			# Maximum volume fraction per species
asmax           = 0.63					# Maximum total volume fraction
distribution    = 'linear'     				# 'linear' or 'log' for alpha distribution
npoints   	= 11					# Number of volume fractions, must be > 1
#nparticles      = 5000					# Total number of particles to use
filestr         = 'Bitest'	  			# Base filename string for input files
binsize         = 0.0001     				# LIGGGHTS parameter neighbor bin, should be a function of the largest sphere diameter 
E		= 8.7e7					# LIGGGHTS parameter Young's modulus for all particles
nu		= 0.3					# LIGGGHTS parameter Poisson's ratio for all particles
steps     	= 10000000      			# Number of simulation steps after initialization
shearStr        = 100.0					# Shear strain rate to apply for shear simulations
lens            = 1e-6                                  # representative length scale, largest length of particle
lebc_band       = 0.15                                  # le band size
lebc_latt       = 10                                    # le lattice size, points per size of smallest particle in the domain
gtemp           = 1.0                                   # granular temperature, used for cooling 
lebuf           = 0.001                                 # percentage of total y-direction length to use as failsafe for LEBC
rinit_xmax      = 0.1                                   # initializer, maximum limit distance/timestep allowed 
rinit_reset     = 100                                   # initializer, number of steps before resetting velocities to zero
rinit_th        = 1e-6                                  # initializer, threshold at which to exit the pre-run step
rinit_ns        = 1e5                                   # initializer, total maximum number of time steps to run the pre-run step
dtrelax         = 1.0                                   # time step relaxation (dt=dtrelax*dt_stable)
npar_max        = 1.1                                   # (ri+rj)*npar_max<check for neighbor list, this works well 
nbins_x = 0
isDimensional = "true"
# MPGCOMMENT 04-21-2023 ---> lebuf will be variable, high in the dilute low in the dense
#############################
minrad = 1e10
maxrad = -1e10
def set_input(nsph_i,proc_i,ptype_i,nspecies_i,diam_i,dens_i,cres_i,amin_i,amax_i,asmax_i,distribution_i,npoints_i,lens_i,lebc_band_i,lebc_latt_i,filestr_i,E_i,nu_i,steps_i,ss_i,gt_i,dtrelax_i,nbinsX_i, isDimensional_i):
  global nspecies
  global gtemp
  global filestr
  global diam
  global dens
  global cres 
  global amin 
  global amax 
  global asmax
  global distribution
  global npoints
  global lens
  global lebc_band
  global lebc_latt
  global binsize
  global ptype
  global proc
  global nsph
  global E
  global nu
  global steps
  global shearStr
  global dtrelax
  global isDimensional
  global is_superquad
  global superquad_values
  is_superquad = []
  superquad_values = []

  nsph=nsph_i
  proc=proc_i
  ptype=ptype_i
  nspecies=nspecies_i
  diam=diam_i
  dens=dens_i
  cres=cres_i
  amin=amin_i
  amax=amax_i
  asmax=asmax_i
  distribution=distribution_i
  npoints=npoints_i
  lens=lens_i
  lebc_band=lebc_band_i
  lebc_latt=lebc_latt_i
  # lens=np.max(np.max(diam[:]),lens)
  global nbins_x
  nbins_x = nbinsX_i
  binsize=15.0*lens/nbins_x # limited later on
  filestr=filestr_i
  E=E_i
  nu=nu_i
  global is_time_test
  is_time_test = False
  if (isinstance(steps_i, str)):
    is_time_test = True
    del steps_i
    steps_i = 100000


  steps=steps_i
  shearStr=ss_i
  gtemp=gt_i
  dtrelax=dtrelax_i
  isDimensional=isDimensional_i

  global global_max_xcm_dis
  global_max_xcm_dis = 0.0

def set_proc(proc_i):
  global proc
  proc=proc_i

def set_lebuf(lebuf_i):
  global lebuf
  lebuf=lebuf_i

def set_init_params(um,re,th,ns):
  global rinit_xmax
  global rinit_reset
  global rinit_th
  global rinit_ns
  global minrad,maxrad 
  rinit_xmax=um
  rinit_reset=re
  rinit_th=th
  rinit_ns=ns
  
  rinit_xmax = min(minrad/10.0,rinit_xmax)

  # xmax = np.max(diam)/rinit_ns/np.max(dt)/10.0
  # print("XMAX: given={0}, computed={1}".format(rinit_xmax,xmax))
  # rinit_xmax=xmax


#####################################################################################################
# Check for errors in input parameters
#####################################################################################################
def check_input():

  print('Checking for input errors ...', end =" ")
  
  if nspecies < 1:
      sys.exit('ERROR: nspecies must be greater than or equal to 1')

  if np.size(diam) != nspecies:
      sys.exit('ERROR: diam must contain nspecies elements')

  if np.size(dens) != nspecies:
      sys.exit('ERROR: dens must contain nspecies elements')

  if np.size(cres) != nspecies:
      sys.exit('ERROR: cres must contain nspecies elements')

  if amin <= 0:
      sys.exit('ERROR: amin must be greater than zero')

  if amin > amax:
      sys.exit('ERROR: amin must be less than amax')

  if asmax < amax:
      sys.exit('ERROR: asmax must be greater than amax')

  if asmax < amin + amax:
      sys.exit('ERROR: asmax must be greater than amax plus amin')

  if distribution not in ['linear', 'log','equal_ratio','curtis_literature']:
      sys.exit('ERROR: distribution must be linear or log')

  if npoints < 2:
      sys.exit('ERROR: npoints must be 2 or greater')

  # if nparticles < nspecies:
  #     sys.exit('ERROR: nparticles must be greater than number of species')

  print(' Done\n')

#####################################################################################################
# general compute functions
#####################################################################################################
def logSpace(a,b,np):
  minISO = log(a)
  maxISO = log(b);
  dx = (maxISO-minISO)/(np-1.);
  ISO = linspace(0,1,np);    
  ISO[np-1] = maxISO;
  for i in range(0,np-1):
    ISO[np-(i+2)] = ISO[np-(i+1)]-dx;
  for i in range(0,np):
    ISO[i] = exp(ISO[i]);        
  return ISO

def pv_from_spheres(xl,yl,zl,rad,latt):
  rsmin = np.min(rad)/latt
  rsmin2 = 0.0
  x_min = np.array([np.min(xl-rad)-rsmin2, np.min(yl-rad)-rsmin2, np.min(zl-rad)-rsmin2])
  x_max = np.array([np.max(xl+rad)+rsmin2, np.max(yl+rad)+rsmin2, np.max(zl+rad)+rsmin2])
  
  nxl = np.array([(x_max[0] - x_min[0])/rsmin-1, (x_max[1] - x_min[1])/rsmin-1, (x_max[2] - x_min[2])/rsmin-1],dtype=int)
  vol=(x_max[0]-x_min[0])*(x_max[1]-x_min[1])*(x_max[2]-x_min[2])
  volp = rsmin*rsmin*rsmin;
  voli = 0.0
  volo = 0.0
  xlshift = np.array([0.5*rsmin,0.5*rsmin,0.5*rsmin])
  ntl = nxl[0]*nxl[1]*nxl[2]
  xloc=np.zeros(int(3))
  gridl=np.zeros(ntl,dtype=int)
  gridl2=np.zeros(ntl,dtype=int)
  ilp=0;
  vfrac=0
  for k in range(0,nxl[2]):
    for j in range(0,nxl[1]):
      for i in range(0,nxl[0]):
        # cell center location
        xloc[0] = x_min[0] + i*rsmin + xlshift[0];
        xloc[1] = x_min[1] + j*rsmin + xlshift[1];
        xloc[2] = x_min[2] + k*rsmin + xlshift[2];
        volo += volp
        # probe point to see if it is within one of the particles of the multisphere
        fp=0
        for p in range(np.size(rad)):
          xp=(xloc[0] - xl[p])
          yp=(xloc[1] - yl[p])
          zp=(xloc[2] - zl[p])
          dist=np.sqrt(xp*xp+yp*yp+zp*zp)
          if (dist<=rad[p]):
            fp=1
            voli += volp
            break
        
        # gridl[ilp] = int(fp)
        gridl2[ilp] = int(fp)
        vfrac=vfrac+fp
        ilp+=1
  return voli
"""
  # compute surface area based on the stair-step mesh
  ilp=0
  for k in range(1,nxl[2]-1):
    for j in range(1,nxl[1]-1):
      for i in range(1,nxl[0]-1):
        lidx0 = i-1 + j*nxl[0] + k*nxl[0]*nxl[1];
        lidx1 = i+1 + j*nxl[0] + k*nxl[0]*nxl[1];
        lidy0 = i + (j-1)*nxl[0] + k*nxl[0]*nxl[1];
        lidy1 = i + (j+1)*nxl[0] + k*nxl[0]*nxl[1];
        lidz0 = i + j*nxl[0] + (k-1)*nxl[0]*nxl[1];
        lidz1 = i + j*nxl[0] + (k+1)*nxl[0]*nxl[1];
        nne = 0
        if (gridl2[ilp]):
          if (not gridl2[lidx0]):
            nne+=1
          if (not gridl2[lidx1]):
            nne+=1
          if (not gridl2[lidy0]):
            nne+=1
          if (not gridl2[lidy1]):
            nne+=1
          if (not gridl2[lidz0]):
            nne+=1
          if (not gridl2[lidz1]):
            nne+=1
        gridl[ilp] = nne
        ilp+=1
  
  areai = 0.0
  for i in range(0,ntl):
    areai += gridl[i]
  areai*=rsmin*rsmin
  spher=np.cbrt(36.*np.pi*voli*voli)/areai
  return voli, spher
"""
#1.0*vfrac/ilp

def particle_volume(bid):
  global minrad,maxrad
  global is_superquad
  global pmode
  global superquad_values
  global global_max_xcm_dis

  if pmode[bid] == 2:
    print("found superquadric")
    is_superquad.append(True)
    strvals = str(ptype[bid]).split()
    this_superquad = [float(strvals[1]),float(strvals[2]),float(strvals[3]),float(strvals[4]),float(strvals[5])]
    superquad_values.append(this_superquad)
    minrad=np.min(np.array([float(strvals[1]),float(strvals[2]),float(strvals[3])]))
    maxrad=np.max(np.array([float(strvals[1]),float(strvals[2]),float(strvals[3])]))
    minrad = minrad * 1.1
    maxrad = maxrad * 1.1

    vol1 = superquadrics.volume([this_superquad[0],this_superquad[1],this_superquad[2],2.0/this_superquad[3],2.0/this_superquad[4]])
    print(vol1)
    global_max_xcm_dis = maxrad

    return vol1

  else:
    is_superquad.append(False)
    superquad_values.append([])
  if (nsph[bid]<=1):
    return 4.0/3.0 * np.pi * (diam[bid]/2.0) ** 3
  ncols=4
  

 

  fin = open(ptype[bid], 'r')
  # check if file exists
  file_ex = exists(ptype[bid])
  if (not file_ex):
    print('ERROR: particle file {0} not present'.format(str(ptype[bid])))
  
  numHeader = int(0)
  xl=[]
  yl=[]
  zl=[]
  rad=[]
  for line in fin.readlines():
    fields = line.split()
    if len(fields) != ncols:
      continue
    try:
      xl.append(float(fields[0]))
      yl.append(float(fields[1]))
      zl.append(float(fields[2]))
      rad.append(float(fields[3]))
    except:
      numHeader += 1
    fin.close()

  xl=np.array(xl)
  yl=np.array(yl)
  zl=np.array(zl)

  x = np.array(xl)
  y = np.array(yl)
  z = np.array(zl)
  r = np.array(rad)

  x = x - np.mean(x)
  y = y - np.mean(y)
  z = z - np.mean(z)

  # for (xx,yy,zz,rr) in zip(x,y,z,r):
  #     print('{:.2e}'.format(xx),'{:.2e}'.format(yy),'{:.2e}'.format(zz),'{:.2e}'.format(rr))

  # print("AABB box lengths")
  # print(np.max(x)-np.min(x))
  # print(np.max(y)-np.min(y))
  # print(np.max(z)-np.min(z))

  max_dis = 0
  max_xcm_dis = 0


  xcm = np.mean(x)
  ycm = np.mean(y)
  zcm = np.mean(z)

  for (xx1,yy1,zz1,rr1) in zip(x,y,z,r):
      cm_distance = math.sqrt((xx1-xcm)**2 + (yy1-ycm)**2 + (zz1-zcm)**2)
      max_xcm_dis = max(cm_distance,max_xcm_dis)

      for (xx2,yy2,zz2,rr2) in zip(x,y,z,r):
          distance = math.sqrt((xx1-xx2)**2 + (yy1-yy2)**2 + (zz1-zz2)**2)
          max_dis = max(distance,max_dis)


  

  global_max_xcm_dis = max(global_max_xcm_dis, max_xcm_dis)

  # print("max distance from any two atoms")
  # print(max_dis)
  # print("max distance from xcm to furthest atom")
  # print(max_xcm_dis)

  # print("expected min bin size")
  # print(max(np.max(r) * 2 * 1.1, max_xcm_dis * 1.1))




  rad=np.array(rad)
  minrad=np.min(rad)
  maxrad=np.max(rad)
  # print(minrad)
  nsph[bid] = np.size(xl)
  residual=1.0
  vol1=1.0
  ii=2
  itn=0
  sphty = 1.0
  while residual>1e-3 and itn<3:
    vol0=vol1
    # vol1,sphty=pv_from_spheres(xl,yl,zl,rad,ii**(2))
    vol1=pv_from_spheres(xl,yl,zl,rad,ii**(2))
    residual=abs(vol1-vol0)/vol1
    # print("residual={0:.3e} , volume= {1:.3e}, sphericity= {2:.3e}".format(residual,vol1,sphty))
    ii+=1
    itn+=1
    # print(minrad)
  vsp = 0.0
  for i in range(0,np.size(xl)):
    vsp+=4.0/3.0 * np.pi * (rad[i]) ** 3
    # print("Body {0} volume= {1:.3e}, sum_sph_vol={2:.3e}, d={3:.3e}, sphericity={4:.3e}".format(ptype[bid],vol1,vsp,2.0*np.cbrt(3.0/4.0*vol1/np.pi), sphty))
  print("Body {0} volume= {1:.3e}, sum_sph_vol={2:.3e}, d={3:.3e}, minR={4:.3e}".format(ptype[bid],vol1,vsp,2.0*np.cbrt(3.0/4.0*vol1/np.pi),minrad))
  return vol1

############ lattice method, create initializer here -> file for max
def lattice_method(bid):

  if (nsph[bid]<=1):
    return 0
  lo = np.array([0.0,0.0,0.0])
  ncols=4
    
  fin = open(ptype[bid], 'r')
  # check if file exists
  file_ex = exists(ptype[bid])
  if (not file_ex):
    print('ERROR: particle file {0} not present'.format(str(ptype[bid])))
  
  numHeader = int(0)
  xl=[]
  yl=[]
  zl=[]
  rad=[]
  for line in fin.readlines():
    fields = line.split()
    if len(fields) != ncols:
      continue
    try:
      xl.append(float(fields[0]))
      yl.append(float(fields[1]))
      zl.append(float(fields[2]))
      rad.append(float(fields[3]))
    except:
      numHeader += 1
    fin.close()

  latt = 10
  xl=np.array(xl)
  yl=np.array(yl)
  zl=np.array(zl)
  rad=np.array(rad)

  rsmin = np.min(rad)/latt
  rsmin2 = rsmin
  x_min = np.array([np.min(xl-rad)-rsmin2, np.min(yl-rad)-rsmin2, np.min(zl-rad)-rsmin2])
  x_max = np.array([np.max(xl+rad)+rsmin2, np.max(yl+rad)+rsmin2, np.max(zl+rad)+rsmin2])

  domain_x = 15*lens
  domain_y = 15*lens
  domain_z = 15*lens
  
  nxl = np.array([(x_max[0] - x_min[0])/rsmin-1, (x_max[1] - x_min[1])/rsmin-1, (x_max[2] - x_min[2])/rsmin-1],dtype=int)
  vol=(x_max[0]-x_min[0])*(x_max[1]-x_min[1])*(x_max[2]-x_min[2])
  volp = rsmin*rsmin*rsmin;
  voli = 0.0
  volo = 0.0
  xlshift = np.array([0.5*rsmin,0.5*rsmin,0.5*rsmin])
  ntl = nxl[0]*nxl[1]*nxl[2]
  xloc=np.zeros(int(3))
  gridl=np.zeros(ntl,dtype=int)
  gridl_buf=np.zeros(ntl,dtype=int)
  gridl2=np.zeros(ntl,dtype=int)
  ilp=0;
  vfrac=0
  for k in range(0,nxl[2]):
    for j in range(0,nxl[1]):
      for i in range(0,nxl[0]):
        # cell center location
        xloc[0] = x_min[0] + i*rsmin + xlshift[0];
        xloc[1] = x_min[1] + j*rsmin + xlshift[1];
        xloc[2] = x_min[2] + k*rsmin + xlshift[2];
        # probe point to see if it is within one of the particles of the multisphere
        fp=0
        for p in range(np.size(rad)):
          xp=(xloc[0] - xl[p])
          yp=(xloc[1] - yl[p])
          zp=(xloc[2] - zl[p])
          dist=np.sqrt(xp*xp+yp*yp+zp*zp)
          if (dist<=rad[p]):
            fp=1
            break
        
        gridl_buf[ilp] = int(fp)
        gridl2[ilp] = gridl_buf[ilp]
        ilp+=1

  for k in range(0,nxl[2]):
    for j in range(0,nxl[1]):
      for i in range(0,nxl[0]):
        # cell center location
        xloc[0] = x_min[0] + i*rsmin + xlshift[0];
        xloc[1] = x_min[1] + j*rsmin + xlshift[1];
        xloc[2] = x_min[2] + k*rsmin + xlshift[2];
        lidx0 = i-1 + j*nxl[0] + k*nxl[0]*nxl[1];
        lidx1 = i+1 + j*nxl[0] + k*nxl[0]*nxl[1];
        lidy0 = i + (j-1)*nxl[0] + k*nxl[0]*nxl[1];
        lidy1 = i + (j+1)*nxl[0] + k*nxl[0]*nxl[1];
        lidz0 = i + j*nxl[0] + (k-1)*nxl[0]*nxl[1];
        lidz1 = i + j*nxl[0] + (k+1)*nxl[0]*nxl[1];
        if (i==0):
          lidx0 = lidx1
        elif (i==nxl[0]-1):
          lidx1 = lidx0

        if (j==0):
          lidy0 = lidy1          
        elif (j==nxl[1]-1):
          lidy1 = lidy0

        if (k==0):
          lidy0 = lidz1
        elif (k==nxl[2]-1):
          lidz1 = lidz0

        ilpp = i + j*nxl[0] + k*nxl[0]*nxl[1];
        if ((gridl_buf[lidx0] or gridl_buf[lidx1] or
             gridl_buf[lidy0] or gridl_buf[lidy1] or
             gridl_buf[lidz0] or gridl_buf[lidz1]) and 
            (not gridl2[ilpp])):
          gridl2[ilpp] = 2;
	  

  for k in range(0,nxl[2]):
    for j in range(0,nxl[1]):
      for i in range(0,nxl[0]):
        lidx0 = i-1 + j*nxl[0] + k*nxl[0]*nxl[1];
        lidx1 = i+1 + j*nxl[0] + k*nxl[0]*nxl[1];
        lidy0 = i + (j-1)*nxl[0] + k*nxl[0]*nxl[1];
        lidy1 = i + (j+1)*nxl[0] + k*nxl[0]*nxl[1];
        lidz0 = i + j*nxl[0] + (k-1)*nxl[0]*nxl[1];
        lidz1 = i + j*nxl[0] + (k+1)*nxl[0]*nxl[1];
        if (i==0):
          lidx0 = lidx1
        elif (i==nxl[0]-1):
          lidx1 = lidx0

        if (j==0):
          lidy0 = lidy1          
        elif (j==nxl[1]-1):
          lidy1 = lidy0

        if (k==0):
          lidy0 = lidz1
        elif (k==nxl[2]-1):
          lidz1 = lidz0

        ilpp = i + j*nxl[0] + k*nxl[0]*nxl[1];
        gridl[ilpp] = gridl2[ilpp]
        icount = 0
        if (gridl2[lidx0]):
          icount+=1
        if (gridl2[lidx1]):
          icount+=1
        if (gridl2[lidy0]):
          icount+=1
        if (gridl2[lidy1]):
          icount+=1
        if (gridl2[lidz0]):
          icount+=1
        if (gridl2[lidz1]):
          icount+=1
        if (icount>2 and (not gridl2[ilpp])):
          gridl[ilpp] = 2


  #  gridl map is how the local processor grid is searched and filled, from particle bounding box grid            
  rsmax = np.max(rad)
  max_part = ((domain_x - 0.0)/(x_max[0] - x_min[0]) *  
              (domain_y - 0.0)/(x_max[1] - x_min[1]) * 
              (domain_z - 0.0)/(x_max[2] - x_min[2]))
  
  xlocg_x = np.zeros(int(5*max_part)) # this should contain the final COM of body for all processors
  xlocg_y = np.zeros(int(5*max_part)) # this should contain the final COM of body for all processors
  xlocg_z = np.zeros(int(5*max_part)) # this should contain the final COM of body for all processors


  # MPGCOMMENT 01-12-2023 ---> have root processor propagate through all particles in the domain, store then send to all other processors
  nx = np.array([(domain_x - 0.0)/rsmin-1, 
                 (domain_y - 0.0)/rsmin-1, 
                 (domain_z - 0.0)/rsmin-1],dtype=int)
  print("box: [{0} {1} {2}] , nxl= [{3} {4} {5}]".format(nx[0],nx[1],nx[2],nxl[0],nxl[1],nxl[2]))
  nt = nx[0]*nx[1]*nx[2];
  ijkc = np.array([nxl[0]/2,nxl[1]/2,nxl[2]/2],dtype=int)
  gridg = np.zeros(nt,dtype=int) #global (within cpu partition)
  for i in range(0,nt):
    gridg[i] = 0
  ilp=0;
  cper = 5
	
  # then fill up the rest with particles as best possible
  for k in range(0,nx[2]):
    for j in range(0,nx[1]):
      for i in range(0,nx[0]):

        if ((i<2 or  i>nx[0]-2) or
            (j<2 or  j>nx[1]-2) or
            (k<2 or  k>nx[2]-2) ):
          continue;


        gid0 = j + i* nx[1] + k* nx[0]* nx[1];

        if (gridg[gid0]):
          continue;
        # ok now, assuming this ijk is the center of the body in its default position, go through the local grid and check to see if any points overlap
        # copy global grid to local and check overlap on local. 	    
        overlap = 0;
        for kp in range(0,nxl[2]):
          if (overlap):
            break
          for jp in range(0,nxl[1]):
            if (overlap):
              break
            for ip in range(0,nxl[0]):
              lid = ip + jp*nxl[0] + kp*nxl[0]*nxl[1];# for local grid
              if (not gridl[lid]):
                continue
              # global index
              ii = ip+i-ijkc[0];
              jj = jp+j-ijkc[1];
              kk = kp+k-ijkc[2];
              if (ii>=nx[0]):
                ii=ii-nx[0]
              if (ii<0):
                ii=ii+nx[0];

              if (jj>=nx[1]):
                jj=jj-nx[1]
              if (jj<0):
                jj=jj+nx[1]

              if (kk>=nx[2]): 
                kk=kk-nx[2]
              if (kk<0):
                kk=kk+nx[2];

              gid = jj + ii* nx[1] + kk* nx[0]* nx[1];# for global grid
              if (gid>=nt or gid<0 or (ii<0 or jj<0 or kk<0)
                  or (ii>=nx[0] or jj>=nx[1] or kk>=nx[2])):
                continue;
		
              if (gridl[lid] and gridg[gid]):
                overlap=1
                break


        ncom = float(gid0*100.0)/float(nt)
        if (ncom%5==0 and ncom==cper):
          print("lattice_init: {0}% \n".format(ncom))
          cper=cper+5;
        if (not overlap):
          # startup location
          xlocg_x[ilp] = lo[0] + i*rsmin + xlshift[0]
          xlocg_y[ilp] = lo[1] + j*rsmin + xlshift[1]
          xlocg_z[ilp] = lo[2] + k*rsmin + xlshift[2];
          # do local shifts and perform checks against all potential particle positions
          # +- shifts in xyz in incremental steps until no overlap is present, set a constant dustance
          ilp=ilp+1
          # copy flag data from particle-local grid to global grid

          for kp in range(0,nxl[2]):
            if (overlap):
              break
            for jp in range(0,nxl[1]):
              if (overlap):
                break
              for ip in range(0,nxl[0]):
                lid = ip + jp*nxl[0] + kp*nxl[0]*nxl[1];# for local grid
                if (not gridl[lid]):
                  continue
                # global index
                ii = ip+i-ijkc[0];
                jj = jp+j-ijkc[1];
                kk = kp+k-ijkc[2];
                if (ii>=nx[0]):
                  ii=ii-nx[0]
                if (ii<0):
                  ii=ii+nx[0];
                
                if (jj>=nx[1]):
                  jj=jj-nx[1]
                if (jj<0):
                  jj=jj+nx[1]
                
                if (kk>=nx[2]): 
                  kk=kk-nx[2]
                if (kk<0):
                  kk=kk+nx[2];

                
                gid = jj + ii* nx[1] + kk* nx[0]* nx[1] # for global grid
                if (gid>=nt or gid<0):
                  continue
                if (gridl[lid]==1):
                  gridg[gid] = 1;
                else:
                  gridg[gid] = gridg[gid];
	      

  print("Maximum number of particles possible: ".format(ilp));
  
#####################################################################################################
# global variables
#####################################################################################################
# new global variables
alpha=[]
alphat=[]
volume_fractions=[]
# count=[]
# vol=[]
# domain=[]
# side=[]
dt=[]
dts=[]
shearCor     = ''
shearCor2    = ''
shearCof     = ''
shearCrl     = ''
shearStrE    = ''
shearStrnu   = ''
shearStrE2    = ''
shearStrnu2   = ''
shearCorM     = ''
shearCorM2     = ''
shearCofM     = ''
shearCrlM     = ''
tsize = 0
pmode=[]
sphericity=[]
psphericity=[]
mstt=0
nd_diam = 0.0
nd_dens = 0.0
tlog=0
notry=[]
#####################################################################################################
# Calculations to set parameters specified in inputs
#####################################################################################################
def calculate_params():
  print('Computing parameters needed for LIGGGHTS input files ...')
  mst=0
  global pmode
  global mstt
  pmode=np.zeros(nspecies)
  global sphericity
  global psphericity
  sphericity=np.zeros(nspecies)  
  psphericity=np.zeros(nspecies)
  print('\nWARNING: sphericity and perpendicular sphericity are being set to 1 ... need a way to specify or compute\n')
  for i in range(0,nspecies):
    sphericity[i] = 1.0
    psphericity[i] = 1.0
    pmode[i] = 0;
    if ptype[i].split()[0] == "superquadric":
      pmode[i] = 2;
    elif ptype[i] != "":
      # check if file exists
      file_ex = exists(ptype[i])
      if (not file_ex):
        print('ERROR: particle file {0} not present'.format(str(ptype[i])))
      pmode[i] = 1;
      mst=mst+1
  mstt=mst
  global nd_dens
  global nd_diam
  nd_diam=0.0
  nd_dens=0.0
  min_radius=1e10
  max_radius=-1e10
  global minrad,maxrad
  for i in range(0,nspecies):        
    diam[i]=2.0*np.cbrt(3.0/4.0*particle_volume(i)/np.pi)
    print(min_radius)
    print(minrad)
    min_radius = min(min_radius,minrad) #minrad is modified inside particle_volume calculations
    max_radius = max(max_radius,maxrad) #minrad is modified inside particle_volume calculations
    nd_diam+=diam[i]
    nd_dens+=dens[i]
  nd_diam=nd_diam/float(nspecies)
  nd_dens=nd_dens/float(nspecies)
  global binsize,nbins_x
  # # binsize =2.1*max_radius #3.0*np.max(diam)
  # # binsize =2.0*np.max(diam)
  # binsize=15.0*lens/nbins_x # obviously, this cannot be smaller than 2*largest_rad. For multisphere, the same applies.
  # if (binsize<2.0*max_radius):
  #   nbins_x_old = nbins_x
  #   nbins_x = math.floor(15.0*lens/(2.0*max_radius))
  #   if (nbins_x % 2 == 0):
  #     print("Nbins changed from {0} to {1}".format(nbins_x_old,nbins_x))
  #   else:
  #     nbins_x+=1
  #     print("Nbins changed from {0} to {1}".format(nbins_x_old,nbins_x))
  # binsize=15.0*lens/nbins_x
  


  global global_max_xcm_dis

  binsize = max_radius * 2.01

  #different bin size calucations, rewrites old stuff
  #binsize = max(max_radius * 2 * 1.1, global_max_xcm_dis * 1.1)



  minrad = min_radius
  print(minrad)
  maxrad = max_radius
  # Particle volume
  vol = np.zeros(nspecies)
  for i in range(0,nspecies):
    vol[i] = (4.0/3.0)*np.pi*(0.5*diam[i])**3

  # Determine volume fraction matrix
  global alpha  
  global alphat  
  global volume_fractions
  alpha = np.zeros((npoints**nspecies,nspecies))
  alphat = np.zeros((npoints**nspecies,nspecies))

  if distribution == 'linear':
      temp = np.linspace(amin,amax,npoints)
      volume_fractions=np.linspace(amin,amax,npoints)
      tlog = 0
  elif distribution == 'log':
      temp = np.geomspace(amin,amax,npoints)
      volume_fractions=logSpace(amin,amax,npoints)
      tlog = 1
  elif distribution == 'equal_ratio':
      temp = np.linspace(amin,amax,npoints)
      volume_fractions=np.linspace(amin,amax,npoints)
      tlog = 0
  elif distribution == 'curtis_literature':
      temp = np.array([0.025,0.05,0.1,0.2,0.3,0.4,0.45,0.5])
      volume_fractions = np.array([0.025,0.05,0.1,0.2,0.3,0.4,0.45,0.5])
      tlog = 0

  for j in range(0,nspecies):
      for i in range(0,npoints**nspecies):
          if j == 0:
              alphat[i,j] = temp[i%npoints]
          else:
              alphat[i,j] = temp[(i%(npoints**(j+1)))//(npoints**j)]

  # Remove overloaded volume fractions
  j = 0
  for i in range(0,npoints**nspecies):
      if np.sum(alphat[i]) < asmax:
          alpha[j] = alphat[i]
          j       += 1

  alpha = np.delete(alpha,np.s_[j:],axis=0)
  global tsize 
  tsize = j

  if distribution == 'equal_ratio':
    tsize = npoints
    alpha = np.zeros((npoints,nspecies))
    alphat = np.zeros((npoints,nspecies))
    
    for i in range(0,npoints):
        for j in range(0,nspecies):
          alphat[i,j] = volume_fractions[i] / float(nspecies)
          alpha[i,j] = volume_fractions[i] / float(nspecies)


  global dtrelax
  if dtrelax > 0.2:
    print("Changed dtrelax to 0.2, it was larger")
    dtrelax = 0.2

  # Determine time step for each case, use normal elastic constant
  # Scaling by volume fraction improves performance
  global dt
  dt = np.zeros(tsize)
  global dts
  dts = np.zeros(tsize)
  global notry
  notry = np.zeros(tsize)

  global dt_fix_init
  dt_fix_init = np.zeros(tsize)
  for i in range(0,tsize):
    ystar = E/(1.-nu**2.)
    kn    = (4.0/3.0)*ystar*np.sqrt(0.5*np.max(diam)*0.01)
    pmass = np.min(vol*dens)
    m12   = 0.5*pmass
    asum = np.sum(alpha[i,:])
    dt[i] = dtrelax*np.pi*np.sqrt(m12/kn) / asum # /50 here? ask Jason about this
    dt_jason = dt[i]
    
    alphap = 0.1631*nu + 0.876605
    shear_mod = E/(2.*(1.+nu))
    # scale_vf=asum * 50.0 #0.0 # same parameter used by Jason

    #useing the equvalent volume radius? not sure about this
    dts0   = dtrelax * np.pi * np.min(diam)/2.0 * np.sqrt(np.min(dens)/shear_mod) / alphap 

    #using min radius, should always be smaller than above dts0
    dts[i] = dtrelax * np.pi * min_radius * np.sqrt(np.min(dens)/shear_mod) / alphap 
    # print("timestep={0:.3e}, {1:.3e}, {2:.3e}".format(dt[i], dts[i], dts0))
    dt[i] = min(dt[i],min(dts[i],dts0)) # quater of stable dt
    dt[i] = dts[i]
    # print("after timestep={0:.3e}, {1:.3e}".format(dt[i], dts[i]))
    # #dt[i] = dt[i]/np.sum(alpha[i,:])

    #fix init dt values seems to work well with old calculation
    ystar = E/(1.-nu**2.)
    kn    = (4.0/3.0)*ystar*np.sqrt(0.5*np.max(diam)*0.01)
    pmass = np.min(vol*dens)
    m12   = 0.5*pmass
    asum = np.sum(alpha[i,:])
    dt_temp = dtrelax*np.pi*np.sqrt(m12/kn) / asum # /50 here? ask Jason about this
    dt_jason = dt[i]
    
    alphap = 0.1631*nu + 0.876605
    shear_mod = E/(2.*(1.+nu))
    scale_vf=asum * 50.0 #0.0 # same parameter used by Jason
   
    dts0_temp   = dtrelax * np.pi * np.min(diam)/2.0 * np.sqrt(np.min(dens)/shear_mod) / alphap / scale_vf
    dts_temp = dtrelax * np.pi * min_radius * np.sqrt(np.min(dens)/shear_mod) / alphap / scale_vf
    # print("timestep={0:.3e}, {1:.3e}, {2:.3e}".format(dt[i], dts[i], dts0))
    dt_fix_init[i]  = min(dt_temp,min(dts_temp,dts0_temp)) # quater of stable dt

    dt_rayleigh = dts0
    
    dxx = lens*15.0
    max_vel = shearStr / 2.0 * dxx
    

    max_flow_through = max_vel*dt[i]*steps/(dxx)
    dt_hertz = 2.87*(pmass**2.0 / (0.5*np.max(diam)*E**2*max_vel))**0.2
    
    print("DT comparison: dt_jason={1:.3e}, dt_hertz={1:.3e}, dt_rayleigh={1:.3e}".format(dt_jason, dt_hertz, dt_rayleigh))
    print("Case stats({0:2d}): dt={1:.3e}, max_v={2:.3e}, fl_through={3:.3e}".format(i,dt[i], max_vel, max_flow_through))

    x0=1e-2
    x1=0.5
    y0=50
    y1=3
    m = (y1-y0)/(x1-x0)
    notry[i] = max(int(m*(asum-x1)+y1),2)


  # Set up strings for global properties in shear simulations
  # Use average for coefficient of restitution between dissimilar particles
  global shearCor
  global shearCof
  global shearCrl
  global shearStrE
  global shearStrnu
  global shearStrE2
  global shearStrnu2
  global shearCor2
  global shearCorM
  global shearCorM2
  global shearCofM
  global shearCrlM
  for i in range(0,(nspecies)**2):
      shearCof  = shearCof  + str(0.0) + ' '
      shearCrl  = shearCrl  + str(0.0) + ' '

  for i in range(0,(nspecies+1)**2):
      shearCofM  = shearCofM  + str(0.0) + ' '
      shearCrlM  = shearCrlM  + str(0.0) + ' '

  # cavg = 1.0
  # shearCor = shearCor + str(round(cavg,3)) + ' '
  # shearCor2 = shearCor2 + str(round(cavg,3)) + ' '

  for i in range(0,nspecies):
      for j in range(0,nspecies):
        cavg = 0.5*(cres[i]+cres[j])
        shearCor = shearCor + str(round(cavg,3)) + ' '
        cavg2 = 0.1
        shearCor2 = shearCor2 + str(round(cavg2,3)) + ' '

  cres2	= np.zeros(np.size(cres)+1)
  for i in range(0,nspecies):
    cres2[i] = cres[i]
  cres2[nspecies] = 1.0
  for i in range(0,nspecies+1):
      for j in range(0,nspecies+1):
        cavg = 0.5*(cres2[i]+cres2[j])
        shearCorM = shearCorM + str(round(cavg,3)) + ' '
        cavg2 = 0.1
        shearCorM2 = shearCorM2 + str(round(cavg2,3)) + ' '
        
  for i in range(0,nspecies):
    shearStrE  = shearStrE + '{:.5e}'.format(float(E)) + ' '
    shearStrnu = shearStrnu + str(nu) + ' '

  for i in range(0,nspecies+1):
    shearStrE2 = shearStrE2 + '{:.5e}'.format(float(E)) + ' '
    shearStrnu2 = shearStrnu2 + str(nu) + ' '

  # Print some statistics to screen
  print('\nNumber of data points created: {0}'.format(tsize)) 
  # print('Max single particle count    : {0}'.format(int(np.max(count))))
  # print('Min single particle count    : {0}'.format(int(np.min(count))))
  
  print('\nDone\n')


#####################################################################################################
# Print simulation matrix to file
#####################################################################################################
def print_matrix():
  print('Printing simulation matrix to file ...', end =" ")

  fout = open(filestr+'_matrix','w')
  
  for i in range(0,nspecies):
      fout.write('    d{0}          n{0}        alph{0}     '.format(i+1))
  fout.write(' sim. vol    alph_tot\n')

  # for i in range(0,tsize):
  #     for j in range(0,nspecies):
  #         fout.write('{0:.5e} {1:.5e} {2:.5e} '.format(diam[j],count[i,j],count[i,j]*vol[j]/domain[i]))
  #     fout.write('{0:.5e} {1:.5e}\n'.format(domain[i],np.sum(count[i,:]*vol[:]/domain[i])))
  fout.close

  print(' Done\n')

#####################################################################################################
# Generate LIGGGHTS shear simulation input files
#####################################################################################################
def shear_sim_files():
  print('Generating {0} LIGGGHTS shear simulation input files ...'.format(tsize), end =" ")

  for j in range(0,tsize):
    shear_sim_files_specific(j)

  print(' Done\n')

def shear_sim_files_specific(j):
  fout = open('in.shear.'+filestr+'_'+str(j),'w')

  fout.write('# LIGGGHTS shear simulation input file\n\n')

  fout.write('# General simulation options\n')
  if pmode[0] == 2:
    fout.write('atom_style        superquadric\n')
  else: 
    fout.write('atom_style        granular\n')
  fout.write('boundary          p p p\n')  
  fout.write('newton            off\n')
  fout.write('echo              both\n')
  fout.write('communicate       single vel yes\n')
  fout.write('units             si\n')
  fout.write('log               log.shear.{0}_{1}.liggghts\n'.format(filestr,str(j)))
  fout.write('atom_modify       map array\n\n')
  fout.write('processors        {0} {1} {2}\n\n'.format(proc[0],proc[1],proc[2]))

  fout.write('# Set domain\n')
  size = lens
  if distribution == "curtis_literature":
    size = diam[0] * 1.05  #the ~15 number is actually around 15.7 * equiv volume diameter
    # if pmode[0] == 2:
    #   size = size * 1.5
  fout.write('region            domain block 0.0 {0:.5e} 0.0 {1:.5e} 0.0 {2:.5e} units box volume_limit 1e-16\n'.format(15.0*size,15.0*size,7.5*size))

  if (lebc_latt):
    fout.write('create_box        {0} domain\n\n'.format(nspecies))
  else:
    fout.write('create_box        {0} domain\n\n'.format(nspecies+1))
  fout.write('# Set neighbor and list options\n')

  if pmode[0] != 2:
    fout.write('neighbor          {0:.3e} bin\n'.format(binsize))
  # fout.write('neighbor          {0:.3e} bin\n'.format(binsize))
  
  # fout.write('neighbor          {0:.3e} multi\n'.format(binsize))
  
  # fout.write('neigh_modify      every 1 delay 0 check no one {0} page {1}\n\n'.format(npar_max,51*npar_max))
    fout.write('neigh_modify      every 1 delay 0 check no contact_distance_factor {0:.1e}\n\n'.format(npar_max))
  else:
    fout.write('neighbor          {0:.3e} bin\n'.format(binsize / 2.0))
    fout.write('neigh_modify      every 1 delay 0 check no\n')

  fout.write('# Set particle properties\n')
  fout.write('hard_particles    yes\n')
  if (lebc_latt):
    fout.write('fix               m1 all property/global youngsModulus peratomtype {0}\n'.format(shearStrE))
    fout.write('fix               m2 all property/global poissonsRatio peratomtype {0}\n'.format(shearStrnu))
    fout.write('fix               m3 all property/global coefficientRestitution peratomtypepair {0} {1}\n'.format(nspecies,shearCor))
    fout.write('fix               m4 all property/global coefficientFriction peratomtypepair {0} {1}\n'.format(nspecies,shearCof))
    fout.write('fix               m5 all property/global coefficientRollingFriction peratomtypepair {0} {1}\n\n'.format(nspecies,shearCrl))
  else:
    fout.write('fix               m1 all property/global youngsModulus peratomtype {0}\n'.format(shearStrE2))
    fout.write('fix               m2 all property/global poissonsRatio peratomtype {0}\n'.format(shearStrnu2))
    fout.write('fix               m3 all property/global coefficientRestitution peratomtypepair {0} {1}\n'.format(nspecies+1,shearCorM))
    fout.write('fix               m4 all property/global coefficientFriction peratomtypepair {0} {1}\n'.format(nspecies+1,shearCofM))
    fout.write('fix               m5 all property/global coefficientRollingFriction peratomtypepair {0} {1}\n\n'.format(nspecies+1,shearCrlM))

    

  fout.write('# Set collision models and time step\n')
  
  if pmode[0] == 2:
    fout.write('pair_style        gran model hertz tangential history surface superquadric\n')
  else:
    fout.write('pair_style        gran model hertz tangential history\n')
  fout.write('pair_coeff        * *\n')
  # dtj = dt[j]/10.0
  fout.write('timestep          {0:.4e}\n\n'.format(1e-16))

  fout.write('# Set up particle templates, distributions, and groups\n')
  ims=1


  global superquad_values
  for i in range(0,nspecies):
    fout.write('group             nve_group{0} region domain\n'.format(i+1))
    if (int(pmode[i]) == 2):
      
      print(" test ")
      print(superquad_values)
      fout.write('fix               pts{0} nve_group{0} particletemplate/superquadric 123457 atom_type {0} volume_limit 1e-18 density constant {1:.3f} shape constant {2:.6f} {3:.6f} {4:.6f} blockiness constant {5:.6f} {6:.6f}\n'.format(i+1,dens[i],superquad_values[i][0],superquad_values[i][1],superquad_values[i][2],superquad_values[i][3],superquad_values[i][4]))
    elif (int(pmode[i]) == 1):
      # print(i,pmode[i],dens[i],nsph[i],ptype[i])
      fout.write('fix               pts{0} nve_group{0} particletemplate/multisphere 123457 atom_type {0} volume_limit 1e-18 density constant {1:.3f} nspheres {2} ntry 10000000 spheres file {3} scale 1.0 type {4}\n'.format(i+1,dens[i],nsph[i],ptype[i],ims))
      ims=ims+1
    else:
      fout.write('fix               pts{0} nve_group{0} particletemplate/sphere 123457 atom_type {0} volume_limit 1e-18 density constant {1:.3f} radius constant {2:.6f}\n'.format(i+1,dens[i],0.5*diam[i]))
    fout.write('fix               pdd{0} nve_group{0} particledistribution/discrete 15485867 1 pts{0} 1.0\n'.format(i+1))
  
  fout.write('# Set up particle insertion\n')
  for i in range(0,nspecies):
    fout.write('fix               ins{0} nve_group{0} insert/pack seed 32452867 distributiontemplate pdd{0} maxattempt {1} vel constant 0. 0. 0. &\n'.format(i+1,int(notry[j])))
    fout.write('                  omega constant 0. 0. 0. insert_every once overlapcheck yes all_in yes region domain ntry_mc 100000000 volumefraction_region {0}\n'.format(alpha[j,i]))

  fout.write('# Apply integration fix\n')
  for i in range(0,nspecies):
    if (pmode[i] == 1):
      fout.write('fix               ms nve_group{0} multisphere\n'.format(i+1))
    if (pmode[i] == 2):
      fout.write('fix               ms nve_group{0} nve/superquadric\n'.format(i+1))
    else:
      fout.write('fix               integr{0} nve_group{0} nve/sphere\n'.format(i+1))

  if (not lebc_latt):
    # fout.write('fix               topwall all wall/gran model hertz tangential history primitive type {0} yplane {1:.5e}\n'.format(nspecies+1,15.0*lens))
    # fout.write('fix               botwall all wall/gran model hertz tangential history primitive type {0} yplane 0.0\n\n'.format(nspecies+1))
    fout.write('# Make collisions elastic, set velocity to zero, and repeat to eliminate overlaps\n')
    fout.write('fix               m3 all property/global coefficientRestitution peratomtypepair {0} {1}\n'.format(nspecies+1,shearCorM2))

  fout.write('# Run one step to get particles inserted\n')
  fout.write('thermo_style      custom step\n')
  fout.write('run               1\n\n')

  string0 = ''
  for i in range(0,nspecies):
      string0 = string0 + ' nve_group' + str(i+1)
  fout.write('group             nve_group union{0}\n\n'.format(string0))


  #####
  if (not lebc_latt):
    fout.write('# Make collisions elastic, set velocity to zero, and repeat to eliminate overlaps\n')
    fout.write('fix               m3 all property/global coefficientRestitution peratomtypepair {0} {1}\n'.format(nspecies+1,shearCorM2))
    fout.write('variable          vzero atom 0.0\n')
    fout.write('# Run briefly to eliminate potential overlaps\n')
    fout.write('fix               limcheck all slowinit xmax {0:.2e} reset {1} threshold {2:.2e} start_dt {3:.3e} end_dt {4:.3e}\n'.format(rinit_xmax,int(rinit_reset),rinit_th, 1e-16, dt_fix_init[j])) # should make this available for user to set
    fout.write('run               {0}\n\n'.format(int(rinit_ns)))

    fout.write('# Set restitution and velocity for granular temperature\n')
    fout.write('fix               m3 all property/global coefficientRestitution peratomtypepair {0} {1}\n'.format(nspecies+1,shearCorM))
    # fout.write('unfix             topwall\n')
    # fout.write('unfix             botwall\n')
    fout.write('unfix             limcheck\n')

  # fout.write('timestep          {0:.4e}\n\n'.format(dt[j]))
  # unset ywalls and set correct COR
  fout.write('# Set the top/bottom boundaries as LE\n')
  fout.write('timestep          {0:.4e}\n\n'.format(dt[j]))
  if alpha[j,i] > 0.2:
    fout.write('fix               leboundary all lebc {0} {1} gtemp {2:0.2e}\n'.format(shearStr, isDimensional, 1e-6))
  else:
    fout.write('fix               leboundary all lebc {0} {1} gtemp {2}\n'.format(shearStr, isDimensional, 0.1))
  fout.write('\n# Run desired simulation\n')
  if is_time_test:
    fout.write('info time\n')
    for asdf in range(50):
      fout.write('run 10000\n')
      fout.write('info time\n')
   
    # for asdf in range(15):
    #   fout.write('run 100000\n')
    #   fout.write('info time\n')

  else:
    fout.write('run               {0}\n'.format(steps))

  fout.close


#####################################################################################################
# Generate LIGGGHTS cooling simulation input files
#####################################################################################################
def cooling_sim_files():
  print('Generating {0} LIGGGHTS cooling simulation input files ...'.format(tsize), end =" ")

  for j in range(0,tsize):
      fout = open('in.cooling.'+filestr+'_'+str(j),'w')

      fout.write('# LIGGGHTS shear simulation input file\n\n')

      fout.write('# General simulation options\n')
      fout.write('atom_style        granular\n')
      fout.write('boundary          p p p\n')  
      fout.write('newton            off\n')
      fout.write('echo              both\n')
      fout.write('communicate       single vel yes\n')
      fout.write('units             si\n')
      fout.write('log               log.cooling.{0}_{1}.liggghts\n'.format(filestr,str(j)))
      fout.write('atom_modify       map array\n\n')
      fout.write('processors        {0} {1} {2}\n\n'.format(proc[0],proc[1],proc[2]))

      fout.write('# Set domain\n')
      fout.write('region            domain block 0.0 {0:.5e} 0.0 {1:.5e} 0.0 {2:.5e} units box\n'.format(15.0*lens,15.0*lens,15.0*lens))
      fout.write('create_box        {0} domain\n\n'.format(nspecies))

      fout.write('# Set neighbor and list options\n')
      
      fout.write('neighbor          {0:.3e} bin\n'.format(binsize))
      fout.write('neigh_modify      every 1 delay 0 check no contact_distance_factor {0:.1e}\n\n'.format(npar_max))

      fout.write('# Set particle properties\n')
      fout.write('hard_particles    yes\n')
      fout.write('fix               m1 all property/global youngsModulus peratomtype {0}\n'.format(shearStrE))
      fout.write('fix               m2 all property/global poissonsRatio peratomtype {0}\n'.format(shearStrnu))
      fout.write('fix               m3 all property/global coefficientRestitution peratomtypepair {0} {1}\n'.format(nspecies,shearCor))
      fout.write('fix               m4 all property/global coefficientFriction peratomtypepair {0} {1}\n'.format(nspecies,shearCof))
      fout.write('fix               m5 all property/global coefficientRollingFriction peratomtypepair {0} {1}\n\n'.format(nspecies,shearCrl))

      fout.write('# Set collision models and time step\n')
      fout.write('pair_style        gran model hertz tangential history\n')
      fout.write('pair_coeff        * *\n')
      # dtj = dt[j]/10.0
      fout.write('timestep          {0:.4e}\n\n'.format(1e-16))

      fout.write('# Set up particle templates, distributions, and groups\n')
      ims=1
      for i in range(0,nspecies):
        fout.write('group             nve_group{0} region domain\n'.format(i+1))
        if (int(pmode[i])):
          # print(i,pmode[i],dens[i],nsph[i],ptype[i])
          fout.write('fix               pts{0} nve_group{0} particletemplate/multisphere 123457 atom_type {0} volume_limit 1e-18 density constant {1:.3f} nspheres {2} ntry 10000000 spheres file {3} scale 1.0 type {4}\n'.format(i+1,dens[i],nsph[i],ptype[i],ims))
          ims=ims+1
        else:
          fout.write('fix               pts{0} nve_group{0} particletemplate/sphere 123457 atom_type {0} volume_limit 1e-18 density constant {1:.3f} radius constant {2:.6f}\n'.format(i+1,dens[i],0.5*diam[i]))
        fout.write('fix               pdd{0} nve_group{0} particledistribution/discrete 15485867 1 pts{0} 1.0\n'.format(i+1))
      
      fout.write('# Set up particle insertion\n')
      for i in range(0,nspecies):
        fout.write('fix               ins{0} nve_group{0} insert/pack seed 32452867 distributiontemplate pdd{0} maxattempt {1} vel constant 0. 0. 0. &\n'.format(i+1,int(notry[j])))
        fout.write('                  omega constant 0. 0. 0. insert_every once overlapcheck yes all_in yes region domain ntry_mc 100000000 volumefraction_region {0}\n'.format(alpha[j,i]))

      fout.write('# Apply integration fix\n')
      for i in range(0,nspecies):
        if (int(pmode[i])):
          fout.write('fix               ms nve_group{0} multisphere\n'.format(i+1))
        else:
          fout.write('fix               integr{0} nve_group{0} nve/sphere\n'.format(i+1))

      if (not lebc_latt):
        fout.write('# Make collisions elastic, set velocity to zero, and repeat to eliminate overlaps\n')
        fout.write('fix               m3 all property/global coefficientRestitution peratomtypepair {0} {1}\n'.format(nspecies,shearCor2))

      fout.write('# Run one step to get particles inserted\n')
      fout.write('thermo_style      custom step\n')
      fout.write('run               1\n\n')

      string0 = ''
      for i in range(0,nspecies):
          string0 = string0 + ' nve_group' + str(i+1)
      fout.write('group             nve_group union{0}\n\n'.format(string0))

      #####
      if (not lebc_latt):
        fout.write('# Make collisions elastic, set velocity to zero, and repeat to eliminate overlaps\n')
        fout.write('fix               m3 all property/global coefficientRestitution peratomtypepair {0} {1}\n'.format(nspecies+1,shearCorM2))
        fout.write('variable          vzero atom 0.0\n')
        fout.write('# Run briefly to eliminate potential overlaps\n')
        fout.write('fix               limcheck all slowinit xmax {0:.2e} reset {1} threshold {2:.2e} start_dt {3:.3e} end_dt {4:.3e}\n'.format(rinit_xmax,int(rinit_reset),rinit_th, 1e-16, dt_fix_init[j])) # should make this available for user to set
        fout.write('run               {0}\n\n'.format(int(rinit_ns)))

        fout.write('# Set restitution and velocity for granular temperature\n')
        fout.write('fix               m3 all property/global coefficientRestitution peratomtypepair {0} {1}\n'.format(nspecies+1,shearCorM))
        # fout.write('unfix             topwall\n')
        # fout.write('unfix             botwall\n')
        fout.write('unfix             limcheck\n')

    
      fout.write('# Set the top/bottom boundaries as LE\n')
      fout.write('timestep          {0:.4e}\n\n'.format(dt[j]))
      fout.write('fix               output all cool gtemp {0} multisphere_types {1} lattice {2}\n'.format(gtemp,mstt,lebc_latt))
      fout.write('\n# Run desired simulation\n')
      fout.write('run               {0}\n'.format(steps))

      fout.close

  print(' Done\n')


#####################################################################################################
# Load data simulation data for post-processing
#####################################################################################################
average_cr = []
average_yy = []
average_xy = []

def load_shear_data():
  print('Loading shear simulation data for post-processing  ...', end =" ")

  data0 = []
  global average_yy
  global average_xy
  average_yy = np.zeros(tsize)
  average_xy = np.zeros(tsize)
  ncols=6
  ndcoeff = (nd_dens*nd_diam**2*shearStr**2)
  if not isDimensional:
    ndcoeff = 1.0
  # print(ndcoeff,nd_dens,nd_diam,shearStr)
  for j in range (0, tsize):
    data0.append([])
    for i in range(0, ncols):
        data0[j].append([])
 
    fin = open('log.shear.{0}_{1}.liggghts'.format(filestr,str(j)), 'r')
    numHeader = int(0)
    for line in fin.readlines():
        fields = line.split()
        if len(fields) != ncols +1:
            continue
        try:
            for i in range(ncols):
                data0[j][i].append(float(fields[i +1]))
        except:
            numHeader += 1
        fin.close()


    # Convert to np arrays
    for i in range(ncols):
        data0[j][i] = np.array(data0[j][i])
        
    k_normalized_pyy = data0[j][1]/ndcoeff
    k_normalized_pxy = abs(data0[j][2]/ndcoeff)
    c_normalized_pyy = data0[j][4]/ndcoeff
    c_normalized_pxy = abs(data0[j][5]/ndcoeff)

    normalized_pyy = k_normalized_pyy + c_normalized_pyy
    normalized_pxy = k_normalized_pxy + c_normalized_pxy

    average_yy[j] = np.average(normalized_pyy[-25:])
    average_xy[j] = np.average(normalized_pxy[-25:])

  print(' Done\n')



def load_shear_data_specific(j):
  print('Loading shear simulation data for post-processing  ...', end =" ")

  data0 = []
  global average_yy
  global average_xy
  average_yy = np.zeros(tsize)
  average_xy = np.zeros(tsize)
  ncols=6
  ndcoeff = (nd_dens*nd_diam**2*shearStr**2)
  if not isDimensional:
    ndcoeff = 1.0
  # print(ndcoeff,nd_dens,nd_diam,shearStr)
  for x in range(j+1):
    data0.append([])
  for i in range(0, ncols):
      data0[j].append([])

  fin = open('log.shear.{0}_{1}.liggghts'.format(filestr,str(j)), 'r')
  numHeader = int(0)
  for line in fin.readlines():
      fields = line.split()
      if len(fields) != ncols +1:
          continue
      try:
          for i in range(ncols):
              data0[j][i].append(float(fields[i +1]))
      except:
          numHeader += 1
      fin.close()


  # Convert to np arrays
  for i in range(ncols):
      data0[j][i] = np.array(data0[j][i])
      
  k_normalized_pyy = data0[j][1]/ndcoeff
  k_normalized_pxy = abs(data0[j][2]/ndcoeff)
  c_normalized_pyy = data0[j][4]/ndcoeff
  c_normalized_pxy = abs(data0[j][5]/ndcoeff)

  normalized_pyy = k_normalized_pyy + c_normalized_pyy
  normalized_pxy = k_normalized_pxy + c_normalized_pxy
  

  average_yy[j] = np.average(normalized_pyy[-50:])
  average_xy[j] = np.average(normalized_pxy[-50:])

  print(' Done\n')

def load_cooling_data():
  print('Loading cooling simulation data for post-processing  ...', end =" ")

  data0 = []
  global average_cr
  average_cr = np.zeros(tsize)
  ncols=6
  for j in range (0, tsize):
    data0.append([])
    for i in range(0, ncols):
        data0[j].append([])
 
    fin = open('log.cooling.{0}_{1}.liggghts'.format(filestr,str(j)), 'r')
    numHeader = int(0)
    for line in fin.readlines():
        fields = line.split()
        if len(fields) != ncols:
            continue
        try:
            for i in range(ncols):
                data0[j][i].append(float(fields[i]))
        except:
            numHeader += 1
        fin.close()


    # Convert to np arrays
    for i in range(ncols):
        data0[j][i] = np.array(data0[j][i])
    time0 = data0[j][0]
    theta = data0[j][1] # consistent across all data points
    ndcoeff = 2.*nd_diam/(time0*np.sqrt(theta))
    normalized_cr = data0[j][3] * nd_diam/np.power(theta,1.5) #*ndcoeff
    average_cr[j] = np.average(normalized_cr[-100:])
  print(' Done\n')

##########################################################################
# for checking individual simulations
def load_shear_data_id(caseid):
  print('Loading shear simulation data for post-processing  ...', end =" ")

  ndcoeff = (nd_dens*nd_diam**2*shearStr**2)
  if not isDimensional:
    ndcoeff = 1.0

  print("average e.v.d.: " + str(nd_diam))
  ncols=6
  data0 = []
  j=0
  data0.append([])
  for i in range(0, ncols):
    data0[j].append([])
    
  fin = open('log.shear.{0}_{1}.liggghts'.format(filestr,str(caseid)), 'r')
  numHeader = int(0)
  lcount =int(0)
  for line in fin.readlines():
    fields = line.split()
    if len(fields) != ncols + 1:
      continue
    try:
      for i in range(ncols):
        data0[j][i].append(float(fields[i+1]))
      lcount += 1
    except:
      numHeader += 1
    fin.close()    

  # Convert to np arrays
  for i in range(ncols):
    data0[j][i] = np.array(data0[j][i])
        
  k_normalized_pyy = data0[j][1]/ndcoeff
  k_normalized_pxy = abs(data0[j][2]/ndcoeff)
  c_normalized_pyy = data0[j][4]/ndcoeff
  c_normalized_pxy = abs(data0[j][5]/ndcoeff)
  
  normalized_pyy = k_normalized_pyy + c_normalized_pyy
  normalized_pxy = k_normalized_pxy + c_normalized_pxy
  xaxis=np.linspace(1,lcount,lcount)

  return xaxis,normalized_pyy,k_normalized_pyy,c_normalized_pyy,normalized_pxy,k_normalized_pxy,c_normalized_pxy


def load_cooling_data_id(caseid):
  print('Loading cooling simulation {0} data for post-processing  ...'.format(caseid), end =" ")

  ncols=6
  data0 = []
  j=0
  data0.append([])
  for i in range(0, ncols):
    data0[0].append([])
    
  fin = open('log.cooling.{0}_{1}.liggghts'.format(filestr,str(caseid)), 'r')
  numHeader = int(0)
  for line in fin.readlines():
    fields = line.split()
    if len(fields) != ncols:
      continue
    try:
      for i in range(ncols):
        data0[0][i].append(float(fields[i]))
    except:
      numHeader += 1
    fin.close()


  # Convert to np arrays
  for i in range(ncols):
    data0[0][i] = np.array(data0[0][i])
  theta = gtemp #data0[j][1] # consistent across all data points
  # ndcoeff =  nd_diam/(theta*np.sqrt(theta))
  normalized_cr = data0[0][1]#*ndcoeff
  tt0 = (data0[0][0])[0]
  tt1 = (data0[0][1])[0]
  ndtheta = np.log10(data0[0][1]/tt1)
  ndtime = np.log10(data0[0][0]/tt0)
  return ndtime,ndtheta,data0[0][0],data0[0][3],data0[0][4]



#####################################################################################################
# Plot shear simulation data
#####################################################################################################
def g0(alp, asmx):
  # ratio =  np.min(alp/ asmx,1.0-1e-4);
  #/* MPGCOMMENT 03-29-2016 ---> Sinclair and Jackson et al. (1989) */
  #r     =  (1.0 / ( 1.0 - np.cbrt(ratio) ) );
  #/* MPGCOMMENT 03-29-2016 ---> Made up */
  #r     =  7.0 / 10.0 * (1.0 / ( 1.0 - power(ratio,1./3.) ) );
  # r = 1.0/(1-alp) + 1.5*alp/np.power(1.0-alp,2) + 0.5*np.power(alp,2)/np.power(1.0-alp,3);
  F = (alp*alp - 0.8*alp + 0.636*(0.8-0.636))/(0.8*0.636-0.16-0.636**2)
  for i in range(0,len(F)):
    if (alp[i]<0.4):
      F[i] = 1.0
  r = F*(2.-alp)/(2.*(1.-alp)**3)+(1.-F)*2./(0.636-alp)
  return r;

def monodisperse_compute(alp, ds, rho, T, e, asmx):

  M_PI=np.pi
  eta = 0.5*(1.+e)
  F=1./(eta*(2.-eta)*g0(alp,asmx))*(1.+(8./5.)*eta*alp*g0(alp,asmx))*(1.+(8./5.)*eta*alp*g0(alp,asmx)*(3.*eta-2.))+768.*eta*alp*alp*g0(alp,asmx)/(25.*M_PI)
  gamma=(48./np.sqrt(M_PI))*eta*(1.-eta)*rho*alp*alp*g0(alp,asmx)*np.power(gtemp,1.5)/ds
  pxy=np.sqrt(-F*(5./96.)*rho*np.sqrt(M_PI*gtemp)*ds*(-gamma))  
  dudy = -gamma/pxy

  #/* /\* MPGCOMMENT 03-30-2016 ---> Gidaspower et al. (1994) *\/ */
  # // pressure
  Pcol = 2.0 * g0(alp, asmx) * rho * (alp*alp) * T * (1.0+e); 
  Pkin = rho * alp * T;
  pressure = (Pcol+Pkin);
  # shear
  mucol = (4.0/5.0) * (alp*alp) * rho * ds * g0(alp, asmx) * (1.0+e) * np.sqrt (T/M_PI); 
  mukin = ( 1.0/15.0*np.sqrt(T*M_PI) * rho * ds * g0(alp,asmx) * (1.0+e) * alp*alp +
            1.0/6.0*np.sqrt(T*M_PI) * rho * ds * alp +
            10.0/96.0*np.sqrt(T*M_PI) * rho * ds / (1.0+e)/g0(alp,asmx) );
  shear_visc = (mucol + mukin);


  gamma = 48./np.sqrt(M_PI)*(eta-eta*eta)*rho*alp**2*g0(alp,asmx)*np.power(gtemp,1.5)/nd_diam
  dudy = -gamma/pxy
  ndcoeff = nd_dens*nd_diam**2*dudy*dudy;#*nd_diam**2*shearStr**2)
  pressure=pressure/ndcoeff
  shear_visc=pxy/ndcoeff
  # #bulk
  # bulk_visc = (4.0/3.0) * (alp*alp) * rho * ds * g0(alp,asmx) * (1.0+e) * np.sqrt(T/M_PI);  
  # # thermal
  # kappa_dil = 75.0/384.0 * rho * ds * np.sqrt(M_PI*T);
  # term1 = 2.0/(1.0+e)/g0(alp,asmx)*np.power(1.0+6.0/5.0*(1.0+e)*g0(alp,asmx)*alp,2.0)*kappa_dil;
  # term2 = 2.0*alp*alp*rho*ds*g0(alp,asmx)*(1.0+e)*np.sqrt(T/M_PI);
  # therm_cond = term1+term2;

  # collisional dissipation
  AR_factor = 1.0;
  Utrace = 0.0;
  ndcoeff2 =  nd_diam/(T*np.sqrt(T))
  # coldissipation = (3.0*(1.0-e*e)*g0(alp,asmx)*rho*alp*alp*( 4.0/ds * np.sqrt(T/M_PI) * AR_factor -Utrace)*T)*ndcoeff2 ;
  # coldissipation = 12.0*(1.0-e*e)*g0(alp,asmx)*rho*alp*alp/np.sqrt(M_PI) ;
  coldissipation = 8.0*(1.0-e*e)*g0(alp,asmx)*alp/np.sqrt(M_PI) ;
  return pressure,shear_visc,coldissipation

#######################
def plot_shear_data():
  print('Plotting shear simulation data ...', end =" ")

  global average_yy
  global average_xy
  # reference data from updated kinetic theory ... 

  vfLunmono = np.linspace(1e-3,0.6,100)
  # pressure = []
  # shear_visc = []
  # coldissipation = []
  # pressure, shear_visc, coldissipation=monodisperse_compute(vfLunmono, nd_diam, nd_dens, gtemp, cres[0], asmax)
  pnLunmono, snLunmono, coldissipation=monodisperse_compute(vfLunmono, nd_diam, nd_dens, gtemp, cres[0], asmax)
  
  vfrac = np.zeros(tsize)
  for i in range(0,tsize):
    vfrac[i]=np.sum(alpha[i,:])



  curl_vf = [0.025,0.05,0.1,0.2,0.3,0.4,0.45]
  #stresses xy
  curl_0_xy = [0.18431267635898857, 0.10533966487104529, 0.09104493601081359, 0.1915798671443623, 0.32080276305435673, 0.6490373002283759, 1.0214936003757875]
  curl_1_xy = [0.18367692476011882, 0.09760702116503658, 0.08463205830986278, 0.1611901079542458, 0.41921213773960553, 1.2879637136782673, 3.146242914956905]
  curl_2_xy = [0.18311016735456978, 0.1066595457969883, 0.08208424718225502, 0.15766605794049596, 0.43870675890136124, 1.5780930315790995, 4.327870848966893]
  curl_3_xy = [0.18874054107830066, 0.11974615765895519, 0.08157479841902532, 0.14821534884967988, 0.442685000126121, 1.6505722502853597, 4.687382633867693]
  curl_4_xy = [0.2637930002340734, 0.12547916766519773, 0.08448164151450277, 0.15040874168152926, 0.39937850736643393, 1.4991871185171846, 4.281167837710025]
  curl_5_xy = [0.32328908868525696, 0.18259869014127486, 0.11727442091695756, 0.15494254128609156, 0.3961673212314838, 1.1544599047372266, 2.342318464760482]
  #stresses yy
  curl_0_yy = [0.5656900319112476, 0.36929181249218357, 0.37930530302455695, 0.7585219698293981, 1.428640715619119, 3.136822877318178, 5.0898130552298655]
  curl_1_yy = [0.5563586304922369, 0.35401643400143334, 0.34337368122020173, 0.6938718501732444, 1.648562469649389, 5.2481342812454965, 13.138746662865987]
  curl_2_yy = [0.5717188732159838, 0.3606425615712801, 0.3446365428676307, 0.7018431256406372, 1.8289130557414053, 6.374434848472287, 17.896000134764208]
  curl_3_yy = [0.569509910549374, 0.3677985373849852, 0.33521967994911417, 0.7069983845934169, 1.877948004122656, 6.567859501608791, 18.995213808533574]
  curl_4_yy = [0.7468499557518299, 0.4116384082230158, 0.35798385934003285, 0.696624311780879, 1.7939588565221556, 6.208763335527074, 17.00182810119522]
  curl_5_yy = [1.0101664681952056, 0.6001889445369429, 0.4451240765608879, 0.6469703725119114, 1.4315900744395864, 4.059044620535561, 8.331972972720303]



  rod2_vf = [0.02533,
          0.05016,
          0.09937,
          0.20135,
          0.29942,
          0.39916,
          0.51278]

  rod2_normal =[2.0985,
                1.0669,
                0.7719,
                1.0152,
                1.9158,
                4.2535,
                13.93]
  
  rod6_vf = [
    0.02639,
    0.05138,
    0.09918,
    0.19967,
    0.29766,
    0.40227,
    0.42095,
    0.44532,
    0.45671,
    0.46438]

  rod6_normal = [
    0.42828,
    0.34198,
    0.449,
    0.8323,
    1.2876,
    2.9912,
    3.7171,
    5.149,
    6.339,
    19.253
  ]


  rod4_vf = [
    0.02497,
    0.05071,
    0.09839,
    0.1997 ,
    0.30101,
    0.40075,
    0.47964,
    0.50017
  ]

  rod4_normal = [  
    0.7564,
    0.5088,
    0.474,
    0.9109,
    1.7663,
    3.8864,
    14.428,
    35.295]
  

  rod2_vis = [
    0.6436,
    0.30878,
    0.20375,
    0.25643,
    0.48546,
    1.1089,
    3.6883
    ]


  rod4_vis = [
    0.24964,
    0.15551,
    0.14578,
    0.25643,
    0.48945,
    1.022,
    3.5974,
    8.01
    ]

  rod6_vis = [
    0.14683,
    0.11591,
    0.1411,
    0.2344,
    0.30731,
    0.6794,
    0.7936,
    1.1558,
    1.361,
    4.1325
    ]
 
  ## pressure
  plt.figure(0)
  plt.semilogy(vfLunmono,pnLunmono,'k-', linewidth=8,label='Kinetic Theory')
  plt.semilogy(vfrac,average_yy,'rs', linewidth=2,label='LIGGGHTS '+filestr,markersize=10)
  if filestr == "rod2":
    plt.semilogy(rod2_vf,rod2_normal,'*',color='blue',label='Guo: rod2')
  if filestr == "rod4":
    plt.semilogy(rod4_vf,rod4_normal,'*',color='blue',label='Guo: rod4')
  if filestr == "rod6":
    plt.semilogy(rod6_vf,rod6_normal,'*',color='blue',label='Guo: rod6')
  if filestr == "curl_3":
    plt.semilogy(curl_vf,curl_3_yy,'*',color='blue',label='Suehr: curl_3')
  if filestr == "curl_5":
    plt.semilogy(curl_vf,curl_5_yy,'*',color='blue',label='Suehr: curl_5')
  if filestr == "curl_0" or filestr == "rod5":
    plt.semilogy(curl_vf,curl_0_yy,'*',color='blue',label='Suehr: curl_0 or rod5')
  plt.xlabel(r'$\alpha_{solid}$')
  plt.ylabel(r'$p_{yy}/\left(\rho d^2 \gamma^2\right)$')
  plt.legend()
  plt.savefig('yy_'+filestr+'.png')
  plt.gcf().clear()
  
  ## viscosity
  plt.figure(1)
  plt.semilogy(vfLunmono,snLunmono,'k-', linewidth=8,label='Kinetic Theory')
  plt.semilogy(vfrac,average_xy,'rs', linewidth=2,label='LIGGGHTS '+filestr,markersize=10)
  if filestr == "rod2":
    plt.semilogy(rod2_vf,rod2_vis,'*',color='blue',label='Guo: rod2')
  if filestr == "rod4":
    plt.semilogy(rod4_vf,rod4_vis,'*',color='blue',label='Guo: rod4')
  if filestr == "rod6":
    plt.semilogy(rod6_vf,rod6_vis,'*',color='blue',label='Guo: rod6')
  if filestr == "curl_3":
    plt.semilogy(curl_vf,curl_3_xy,'*',color='blue',label='Suehr: curl_3')
  if filestr == "curl_5":
    plt.semilogy(curl_vf,curl_3_xy,'*',color='blue',label='Suehr: curl_5')
  if filestr == "curl_0" or filestr == "rod5":
    plt.semilogy(curl_vf,curl_0_xy,'*',color='blue',label='Suehr: curl_0 or rod5')
  plt.xlabel(r'$\alpha_{solid}$')
  plt.ylabel(r'$|p_{xy}|/\left(\rho d^2 \gamma^2\right)$')
  plt.legend()
  plt.savefig('xy_'+filestr+'.png')
  plt.gcf().clear()

  print(' Done\n')



def plot_shear_case_data(caseid):
  print('Plotting shear {0} simulation data ...'.format(caseid), end =" ")

  vfrac = np.zeros(tsize)
  for i in range(0,tsize):
    vfrac[i]=np.sum(alpha[i,:])

  # global average_cr
  # reference data from updated kinetic theory ... 
  vfLunmono = np.array([vfrac[caseid]])

  pressure, shear_visc, coldissipation = monodisperse_compute(vfLunmono, nd_diam, nd_dens, gtemp, cres[0], asmax)
  xaxis,normalized_pyy,k_normalized_pyy,c_normalized_pyy,normalized_pxy,k_normalized_pxy,c_normalized_pxy=load_shear_data_id(caseid)
  plt.semilogy(xaxis,normalized_pxy,'r', linewidth=2,label=r'$|p_{xy}|/\left(\rho d^2 \gamma^2\right)$',markersize=10)
  plt.semilogy(xaxis,normalized_pyy,'b', linewidth=2,label=r'$p_{yy}/\left(\rho d^2 \gamma^2\right)$',markersize=10)
  plt.xlabel('Steps x 50k')
  plt.ylabel(r'Normalized Stress')
  plt.legend()
  plt.grid()

  plt.savefig('stress_'+filestr+'_'+str(caseid)+'.png')
  plt.gcf().clear()
  
  print(' Done\n')


def plot_cooling_data():
  print('Plotting cooling simulation data ...', end =" ")

  global average_cr
  # reference data from updated kinetic theory ... 
  # vfLunmono = np.array([0.001, 0.002, 0.005, 0.01, 0.025, 0.04, 0.06, 0.08, 0.1, 0.12, 0.14, 0.16, 0.18, 0.2, 0.22, 0.24,
  #                       0.26, 0.28, 0.3, 0.32, 0.34, 0.36, 0.38, 0.4, 0.42, 0.44, 0.46, 0.48, 0.5, 0.52, 0.54, 0.56, 0.58, 0.6, 0.62])
  vfLunmono = np.linspace(1e-3,asmax-1e-3,100)

  pressure, shear_visc, coldissipation=monodisperse_compute(vfLunmono, nd_diam, nd_dens, gtemp, cres[0], asmax)

  vfrac = np.zeros(tsize)
  for i in range(0,tsize):
    vfrac[i]=np.sum(alpha[i,:])
  ## col dissipation
  plt.figure(0)
  # plt.semilogy(vfrac,average_cr,'sb', linewidth=2,label='LIGGGHTS '+filestr,markersize=6)
  # plt.semilogy(vfLunmono,coldissipation,':k', linewidth=2,label='Kinetic Theory',markersize=12)
  plt.semilogy(vfLunmono,abs(coldissipation),'k-', linewidth=8,label='Kinetic Theory')
  plt.semilogy(vfrac,abs(average_cr),'rs', linewidth=2,label='LIGGGHTS '+filestr,markersize=10)
  plt.xlabel(r'$\alpha_{solid}$')
  plt.ylabel(r'$\gamma d_s/\theta^{1.5}$')
  plt.legend()
  plt.savefig('cr_'+filestr+'.png')
  plt.gcf().clear()

  print(' Done\n')


def plot_cooling_case_data(caseid):
  print('Plotting cooling {0} simulation data ...'.format(caseid), end =" ")

  vfrac = np.zeros(tsize)
  for i in range(0,tsize):
    vfrac[i]=np.sum(alpha[i,:])

  # global average_cr
  # reference data from updated kinetic theory ... 
  vfLunmono = np.array([vfrac[caseid]])

  pressure, shear_visc, coldissipation = monodisperse_compute(vfLunmono, nd_diam, nd_dens, gtemp, cres[0], asmax)
  ctime,acr,stime,dTdt,dTdtl = load_cooling_data_id(caseid)
  # acr[end] + 2*ctime[end] = b
  y=-2.*ctime+(acr[-1] + 2.*ctime[-1])
  # print(ctime)
  # print(acr)
  ## col dissipation
  plt.figure(0)
  plt.plot(ctime,y,'k-', linewidth=12,label='Slope=-2')
  plt.plot(ctime,acr,'r-', linewidth=8,label='LIGGGHTS '+filestr)
  # plt.semilogy(vfLunmono,coldissipation,':k', linewidth=2,label='Kinetic Theory',markersize=12)
  plt.xlabel(r'$log_{10}\left(t/t_0\right)$')
  plt.ylabel(r'$log_{10}\left(\theta/\theta_0\right)$')
  plt.legend()
  plt.savefig('theta_'+filestr+'_'+str(caseid)+'.png')
  plt.gcf().clear()
  
  # for i in range(0,len(y)):
  #   y[i] = -2
  # plt.plot(ctime,y,'k-', linewidth=12,label='HCS')
  # plt.plot(stime,dTdt,'r-', linewidth=8,label='LIGGGHTS '+filestr)
  # # plt.semilogy(vfLunmono,coldissipation,':k', linewidth=2,label='Kinetic Theory',markersize=12)
  # plt.xlabel(r'$t (s)$')
  # plt.ylabel(r'$d\Theta/dt$')
  # plt.legend()
  # plt.ylim([-4,0])
  # plt.savefig('dTdtl_'+filestr+'_'+str(caseid)+'.png')
  # plt.gcf().clear()

  print(' Done\n')


# visually inspect data 
def inspect_data():
  for j in range (0, tsize):
    print("vf,p,mu,cr({4}): {0:.2e}, {1:.2e}, {2:.2e}, {3:.2e}".format(alpha[j,0],average_yy[j],average_xy[j],average_cr[j],j))
#####################################################################################################
# Generate script to collate data and output to file into Loci/GGFS format
#####################################################################################################
def data_to_ggfs(fnameOut):
  print('Generating output data in Loci/GGFS format ...', end =" ")

  # Retrieve data from shear and cooling simulations
  global average_cr
  global average_yy
  global average_xy

  norm_p = np.zeros(npoints**nspecies)
  norm_visc = np.zeros(npoints**nspecies)
  norm_zeta = np.zeros(npoints**nspecies)

  shearFileList   = []
  coolingFileList = []
  j = 0
  for i in range(0,npoints**nspecies):
    if np.sum(alphat[i]) < asmax:
      norm_p[i]=average_yy[j]
      norm_visc[i]=average_xy[j]
      norm_zeta[i]=average_cr[j]
      j+= 1
    else:
      norm_p[i]    = 0.0
      norm_visc[i] = 0.0
      norm_zeta[i] = 0.0

  # Write DEM data to hdf5 file
  hf = h5py.File(fnameOut+'.h5', 'w')

  g1 = hf.create_group('cr')
  g1.create_dataset('data',data=norm_zeta)

  g2 = hf.create_group('sigxx')
  g2.create_dataset('data',data=norm_p)

  g3 = hf.create_group('sigxy')
  g3.create_dataset('data',data=norm_visc)

  g4 = hf.create_group('tableParams')
  tabl = np.array([nspecies,npoints,amin,amax,tlog])
  g4.create_dataset('NsNpMinMaxLog',data=tabl)
  g4.create_dataset('ds',data=diam)
  g4.create_dataset('e',data=cres)
  g4.create_dataset('psphericity',data=psphericity)
  g4.create_dataset('rho',data=dens)
  g4.create_dataset('sphericity',data=sphericity)

  hf.close()
  print(' Done\n')

#####################################################################################################
# Generate PBS scripts to run each simulation
#####################################################################################################
def pbs_files(nnodes,cpn,cpu_tot,model,wtime,queue,group_list,lmp_exec,tmode, module_load_string):
  print('Generating {0} PBS scripts to run each simulation ...'.format(tmode), end =" ")
  for j in range(0,tsize):
      pbs_files_specific(j,nnodes,cpn,cpu_tot,model,wtime,queue,group_list,lmp_exec,tmode, module_load_string)
  print(' Done\n')


def pbs_files_specific(j, nnodes,cpn,cpu_tot,model,wtime,queue,group_list,lmp_exec,tmode, module_load_string):
  print('Generating {0} PBS scripts to run each simulation ...'.format(tmode), end =" ")
 
  fout = open('PBS_'+tmode+'_'+filestr+'_'+str(j)+'.script','w')
  fout.write('########################################\n')
  fout.write('##PBS Controls       \n')
  fout.write('########################################\n')
  fout.write('#PBS -S /bin/bash\n')
  if model == "":
    fout.write('#PBS -l nodes={0}:ppn={1}\n'.format(int(nnodes),int(cpn)))
  else: 
    fout.write('#PBS -l select={0}:ncpus={1}:model={2}\n'.format(int(nnodes),int(cpn),model))
  fout.write('#PBS -l walltime={0}\n'.format(wtime))
  #fout.write('#PBS -q {0}\n'.format(queue))
  fout.write('#PBS -V\n')
  #fout.write('#PBS -r n\n')
  if group_list != "":
    fout.write('#PBS -W group_list={}\n'.format(group_list))
  fout.write('#PBS -N {2}_{0}_{1}\n\n'.format(filestr,str(j),tmode))
  fout.write('########################################\n')
  fout.write('#===================================================================#\n')
  fout.write('# Load modules and move to current directory\n')
  fout.write('#===================================================================#\n\n')
  fout.write(module_load_string)
  fout.write('cd $PBS_O_WORKDIR\n\n')
  fout.write('#===================================================================#\n')
  fout.write('# Run simulation\n')
  fout.write('#===================================================================#\n\n')
  # fout.write('echo "Beginning LIGGGHTS simulation"\n\n')
  fout.write('mpiexec -np {3} {2} < in.{4}.{0}_{1} > stdout_{4}_{0}_{1} \n\n'.format(filestr,str(j),lmp_exec,int(cpu_tot),tmode))
  # fout.write('echo "LIGGGHTS simulation complete"\n\n')
  fout.close

  print(' Done\n')




def del_globals():
  global minrad,maxrad
  global pmode
  global mstt
  global sphericity
  global psphericity
  global nd_dens
  global nd_diam
  global alpha  
  global alphat  
  global volume_fractions
  global shearCor
  global shearCof
  global shearCrl
  global shearStrE
  global shearStrnu
  global shearStrE2
  global shearStrnu2
  global shearCor2
  global shearCorM
  global shearCorM2
  global shearCofM
  global shearCrlM
  global minrad,maxrad
  #####################################################################################################
  # global variables
  #####################################################################################################
  # new global variables
  alpha=[]
  alphat=[]
  volume_fractions=[]
  # count=[]
  # vol=[]
  # domain=[]
  # side=[]
  dt=[]
  dts=[]
  shearCor     = ''
  shearCor2    = ''
  shearCof     = ''
  shearCrl     = ''
  shearStrE    = ''
  shearStrnu   = ''
  shearStrE2    = ''
  shearStrnu2   = ''
  shearCorM     = ''
  shearCorM2     = ''
  shearCofM     = ''
  shearCrlM     = ''
  tsize = 0
  pmode=[]
  sphericity=[]
  psphericity=[]
  mstt=0
  nd_diam = 0.0
  nd_dens = 0.0
  tlog=0
  notry=[]





